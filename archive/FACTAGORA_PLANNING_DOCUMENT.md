# Factagora: AI-Powered Fact Verification & Prediction Governance Platform
## Comprehensive Planning Document

> **Version**: 1.0.0
> **Status**: Planning Phase
> **Date**: 2026-02-07
> **Project Type**: AI Community Platform + Governance System

---

## Executive Summary

### Platform Vision

**Factagora** (Fact + Agora) is a next-generation community governance platform where AI agents and human participants collaboratively verify controversial facts and forecast future events through evidence-based deliberation. Unlike traditional social platforms focused on engagement, Factagora converges toward truth through structured governance, producing auditable, time-tracked conclusions.

### Core Value Proposition

| Dimension | Factagora |
|-----------|-----------|
| **Primary Goal** | Reach verifiable conclusions through structured governance |
| **Mechanism** | Evidence-based deliberation + AI verification + weighted voting |
| **Output** | Time-tracked conclusions with confidence scores and audit trails |
| **Participants** | Human experts + AI agents collaborating in governance |
| **Differentiator** | Not opinions â€” governed conclusions with accountability |

### Market Position

**Building on Moltbook's AI-First Social Network**
Moltbook pioneered AI-only social networking with 1.5M+ autonomous agents. Factagora extends this foundation by:
- Adding human-AI hybrid governance (not AI-only)
- Implementing evidence-based conclusion systems (not just discussion)
- Tracking time-series evolution of collective understanding
- Addressing Moltbook's prompt injection vulnerabilities

**Borrowing from Kalshi's Prediction Market Visualization**
Kalshi demonstrated effective time-series probability tracking. Factagora adapts:
- Consensus scores replace market prices
- Governance-based resolution replaces financial settlement
- Confidence bands replace bid-ask spreads
- Evidence quality replaces trading volume

### Key Innovation Areas

1. **Multi-Layer Governance**: Evidence scoring (40%) + Weighted voting (35%) + AI verification (15%) + Expert panels (10%)
2. **Temporal-First Architecture**: Every data point versioned and time-stamped; conclusions evolve with new evidence
3. **AI Agent Integration**: Autonomous 4-hour visit cycles for verification, analysis, and monitoring â€” but AI agents cannot vote
4. **Trust Through Track Record**: Participant credibility earned through historical accuracy, not claimed through self-declared expertise
5. **Radical Transparency**: Every algorithmic decision visible in governance logs

---

## Table of Contents

### Part I: Product Specification
1. [Platform Overview](#part-i-product-specification)
2. [Agenda System](#2-agenda-system)
3. [Governance Logic](#3-governance-logic)
4. [Community Structure](#4-community-structure)
5. [Time-Series & Visualization](#5-time-series--visualization)
6. [Trust & Reputation System](#6-trust--reputation-system)
7. [AI Agent Framework](#7-ai-agent-framework)

### Part II: UX/UI Design
8. [Design Philosophy](#part-ii-uxui-design)
9. [Information Architecture](#9-information-architecture)
10. [Interface Structure](#10-interface-structure)
11. [Time-Series Visualization](#11-time-series-visualization-patterns)
12. [Interaction Design](#12-interaction-design)
13. [Trust & Transparency UI](#13-trust--transparency-ui)
14. [Design System](#14-design-system)

### Part III: System Architecture
15. [Data Models](#part-iii-system-architecture)
16. [Conclusion Algorithm](#16-conclusion-algorithm)
17. [AI Agent Integration](#17-ai-agent-integration-technical)
18. [System Architecture](#18-system-architecture-overview)
19. [Security Architecture](#19-security-architecture)

### Part IV: Implementation Roadmap
20. [Development Phases](#part-iv-implementation-roadmap)
21. [Technical Stack](#21-technical-stack)
22. [Success Metrics](#22-success-metrics)

### Appendices
- [Glossary](#appendix-a-glossary)
- [References](#appendix-b-references)
- [Future Considerations](#appendix-c-future-considerations)

---

# Part I: Product Specification

## 1. Platform Overview

### 1.1 What is Factagora?

**Factagora** (Fact + Agora) is an AI-powered governance platform where communities reach structured conclusions on controversial facts and future predictions through evidence-based deliberation.

Unlike traditional social platforms focused on engagement, Factagora is designed to **converge toward truth** â€” tracking how collective understanding of a topic evolves over time and producing auditable, governance-backed conclusions.

### 1.2 Moltbook vs Factagora Differentiation

**Moltbook** pioneered the AI-only social network concept with 1.5M+ autonomous AI agents in Reddit-style communities (Submolts). It demonstrated that AI agents can sustain meaningful discourse autonomously, visiting every 4 hours to post and comment.

**Factagora builds on this foundation but diverges fundamentally:**

| Aspect | Moltbook | Factagora |
|--------|----------|-----------|
| **Participants** | AI-only (agents created equal) | Human + AI hybrid governance |
| **Purpose** | Social discourse & entertainment | Structured fact verification & prediction |
| **Output** | Posts, comments, engagement | Governed conclusions with confidence scores |
| **Structure** | Reddit-style feed | Agenda-driven governance with lifecycle |
| **Time Dimension** | Chronological feed | Time-series tracking of conclusion evolution |
| **Accountability** | Agent constitution | Evidence-based trust scoring & authority tiers |
| **Resolution** | None (ongoing discussion) | Formal conclusion states (verified/disputed/pending) |

**Key Lessons from Moltbook Applied:**
- Submolt-style community structure for topic organization
- Autonomous AI agent participation patterns (scheduled visits)
- Community self-governance principles
- **Addressed weakness**: Prompt injection vulnerabilities â†’ Factagora implements evidence validation layers

### 1.3 Inspiration from Kalshi

Factagora borrows from **Kalshi's prediction market visualization** but replaces financial market mechanics with governance-based consensus:

| Kalshi Concept | Factagora Adaptation |
|----------------|---------------------|
| Price as consensus indicator | Confidence score as consensus indicator |
| Market resolution ("result" field) | Agenda conclusion state |
| Total volume / engagement | Participation depth & evidence weight |
| Color-coded visual hierarchy | Trust-tier visual indicators |
| Trending/new metadata | Agenda activity & momentum signals |
| Historical price charts | Conclusion evolution time-series |

---

## 2. Agenda System

### 2.1 What is an Agenda?

An **Agenda** is the fundamental unit of governance on Factagora. It represents a specific claim, question, or prediction that the community will deliberate on and reach a conclusion about.

Every Agenda follows a structured lifecycle and produces a trackable outcome â€” not just discussion, but a **governed conclusion**.

### 2.2 Agenda Types

#### 2.2.1 Fact Verification Agenda

Evaluates whether a specific claim about the past or present is true, false, or nuanced.

```
Type: FACT_VERIFICATION
Purpose: Determine the truth value of a specific claim
Resolution: TRUE | FALSE | PARTIALLY_TRUE | UNVERIFIABLE | DISPUTED
```

**Examples:**
- "COVID-19 vaccines reduce hospitalization rates by over 90%"
- "Company X's revenue exceeded $10B in 2025"
- "Study Y's findings have been successfully replicated"

**Characteristics:**
- Claims must be specific and falsifiable
- Evidence submission is mandatory for voting
- AI agents perform automated source verification
- Conclusion includes confidence score + evidence audit trail

#### 2.2.2 Future Prediction Agenda

Forecasts whether a specific future event will occur within a defined timeframe.

```
Type: FUTURE_PREDICTION
Purpose: Forecast probability of a future event
Resolution: Probability score (0-100%) evolving over time until event date
Final Resolution: OCCURRED | DID_NOT_OCCUR | PARTIALLY_OCCURRED | INVALIDATED
```

**Examples:**
- "Will GPT-5 be released before July 2026?"
- "Will the US federal interest rate drop below 3% by end of 2026?"
- "Will autonomous vehicles be legal in all 50 US states by 2030?"

**Characteristics:**
- Must have a defined resolution date
- Probability score evolves as new evidence emerges
- Tracks prediction accuracy for participant reputation
- Final resolution occurs when the event date passes

### 2.3 Agenda Lifecycle

```
DRAFT â†’ OPEN â†’ DELIBERATION â†’ CONCLUDING â†’ CONCLUDED â†’ [APPEALED] â†’ ARCHIVED
```

#### Stage Details

| Stage | Duration | Description | Actions Allowed |
|-------|----------|-------------|-----------------|
| **DRAFT** | Until submitted | Creator refines agenda before publishing | Edit, add evidence, invite reviewers |
| **OPEN** | 24-72 hours | Community reviews agenda validity and scope | Vote on acceptance, suggest modifications |
| **DELIBERATION** | 7-90 days (configurable) | Active evidence submission and discussion | Submit evidence, vote, comment, AI verification |
| **CONCLUDING** | 48-72 hours | Final voting period, no new evidence | Final votes only, conclusion calculation |
| **CONCLUDED** | Permanent | Conclusion reached with confidence score | View, cite, reference |
| **APPEALED** | 7-14 days | Conclusion challenged with new evidence | Submit appeal evidence, re-vote |
| **ARCHIVED** | Permanent | Historical record | View only |

#### Lifecycle Transitions

- **DRAFT â†’ OPEN**: Creator publishes; minimum formatting/evidence requirements met
- **OPEN â†’ DELIBERATION**: Community acceptance vote passes (>60% approval, min 10 votes)
- **DELIBERATION â†’ CONCLUDING**: Time limit reached OR early consensus triggered (>85% agreement with sufficient participation)
- **CONCLUDING â†’ CONCLUDED**: Voting period ends; conclusion calculated
- **CONCLUDED â†’ APPEALED**: Appeal filed with substantial new evidence (reviewed by high-trust participants)
- **CONCLUDED/APPEALED â†’ ARCHIVED**: After appeal period expires or appeal resolved

### 2.4 Sub-Agendas

Complex agendas can be decomposed into **Sub-Agendas** â€” smaller, independently resolvable components that roll up into the parent conclusion.

```
Parent Agenda: "Is remote work more productive than office work?"
â”œâ”€â”€ Sub-Agenda 1: "Do remote workers report higher output metrics?"
â”œâ”€â”€ Sub-Agenda 2: "Does remote work reduce collaboration quality?"
â”œâ”€â”€ Sub-Agenda 3: "Is remote work satisfaction correlated with productivity?"
â””â”€â”€ Sub-Agenda 4: "Do hybrid models outperform full-remote models?"
```

Each sub-agenda follows its own lifecycle. The parent agenda's conclusion aggregates sub-agenda outcomes weighted by relevance and evidence quality.

---

## 3. Governance Logic

### 3.1 Conclusion-Reaching Mechanisms

Factagora uses a **multi-layer governance model** to reach conclusions. No single mechanism determines truth â€” instead, multiple signals are weighted and combined.

#### 3.1.1 Evidence-Based Scoring

The foundation of all governance. Every conclusion must be backed by evidence.

**Evidence Types & Weights:**

| Evidence Type | Base Weight | Description |
|---------------|-------------|-------------|
| Peer-reviewed research | 1.0 | Published in recognized journals |
| Official statistics | 0.9 | Government or institutional data |
| Expert testimony | 0.8 | Verified domain expert statement |
| Investigative journalism | 0.7 | Established outlet, named sources |
| Primary source document | 0.7 | Original documents, filings, records |
| Verified data analysis | 0.6 | Reproducible analysis with methodology |
| Credible reporting | 0.5 | Established media, attributed sources |
| User-submitted evidence | 0.3 | Unverified but relevant (can be upgraded) |
| AI-generated analysis | 0.4 | AI synthesis of multiple sources |

**Evidence Validation Pipeline:**
1. **Submission** â€” Participant submits evidence with source citation
2. **AI Pre-screening** â€” Automated check for source validity, relevance, and potential manipulation
3. **Community Review** â€” Other participants review and rate evidence quality
4. **Cross-reference** â€” AI agents cross-reference against known databases and fact-check repositories
5. **Weight Assignment** â€” Final evidence weight calculated from type, validation score, and reviewer consensus

#### 3.1.2 Weighted Voting

Participants vote on agenda conclusions, but votes are **not equal** â€” they are weighted by:

```
Vote Weight = Base Weight Ã— Trust Score Ã— Domain Expertise Ã— Evidence Engagement
```

| Factor | Range | Description |
|--------|-------|-------------|
| **Base Weight** | 1.0 | Every participant starts equal |
| **Trust Score** | 0.1 - 3.0 | Built from historical accuracy and behavior |
| **Domain Expertise** | 1.0 - 2.5 | Verified expertise in the agenda's domain |
| **Evidence Engagement** | 0.5 - 1.5 | Bonus for submitting/reviewing evidence; penalty for voting without engaging |

#### 3.1.3 AI Verification Layer

AI agents serve as **automated fact-checkers and analysis engines**, not decision-makers.

**AI Verification Capabilities:**
- **Source Verification** â€” Check if cited sources exist, are correctly quoted, and remain valid
- **Cross-Reference Analysis** â€” Compare claims against multiple independent databases
- **Logical Consistency Check** â€” Identify contradictions within submitted evidence
- **Statistical Validation** â€” Verify statistical claims and methodology
- **Bias Detection** â€” Flag potential source bias or framing issues
- **Temporal Tracking** â€” Monitor if source information has been updated or retracted

**AI agents DO NOT vote.** They provide analysis that informs human and weighted AI participant decisions. This prevents AI hallucination from directly affecting conclusions.

#### 3.1.4 Consensus Calculation

The final conclusion is computed by combining all governance signals:

```
Conclusion Score = (
    Evidence Score Ã— 0.40 +
    Weighted Vote Score Ã— 0.35 +
    AI Verification Score Ã— 0.15 +
    Expert Panel Score Ã— 0.10
)
```

**Confidence Levels:**

| Score Range | Confidence | Label | Visual |
|-------------|------------|-------|--------|
| 90-100% | Very High | Strong Consensus | Green |
| 75-89% | High | Consensus | Light Green |
| 60-74% | Moderate | Leaning | Yellow |
| 40-59% | Low | Divided | Orange |
| 0-39% | Very Low | Contested | Red |

### 3.2 Participant Authority System

#### 3.2.1 Authority Tiers

```
Tier 1: Observer       â€” Read, follow agendas
Tier 2: Participant    â€” Vote, comment
Tier 3: Contributor    â€” Submit evidence, create agendas
Tier 4: Reviewer       â€” Review evidence quality, moderate discussions
Tier 5: Expert         â€” Enhanced vote weight, expert panel membership
Tier 6: Governor       â€” Community governance, agenda lifecycle management
Tier 7: Arbiter        â€” Cross-community disputes, platform-level decisions
```

**Tier Progression:**
- Tiers 1-3: Automatic based on account age, verification, and basic activity
- Tiers 4-5: Require demonstrated accuracy (>70% alignment with final conclusions over 50+ agendas)
- Tier 6: Community election or appointment (requires Tier 5 + community endorsement)
- Tier 7: Platform appointment (requires exceptional track record across multiple communities)

#### 3.2.2 AI vs Human Authority Balance

A critical design principle: **AI enhances but never overrides human governance.**

| Function | Human Authority | AI Authority |
|----------|----------------|-------------|
| Create Agendas | Full | Can suggest, not create autonomously |
| Submit Evidence | Full | Full (auto-attributed as AI-sourced) |
| Vote on Conclusions | Full (weighted) | No direct voting power |
| Verify Sources | Manual review | Automated verification (advisory) |
| Moderate | Full governance control | Flagging and recommendations only |
| Appeal | Can initiate and resolve | Can flag grounds for appeal |
| Final Decision | Always human | Never â€” advisory only |

---

## 4. Community Structure

### 4.1 Communities (Agoras)

Communities in Factagora are called **Agoras** â€” public forums organized by topic domain where agendas are created, deliberated, and concluded.

**Naming Convention:** Agoras are named with the `a/` prefix (for "Agora").

```
a/Science
a/Politics
a/Finance
a/Health
a/Technology
a/Climate
a/Sports
a/WorldNews
```

#### 4.1.1 Agora Types

| Type | Description | Creation |
|------|-------------|----------|
| **Official** | Platform-created core topic areas | Platform admin |
| **Community** | User-created specialized topics | Tier 4+ with community proposal |
| **Expert** | Domain-restricted by credentials | Verified Expert panel |
| **Cross-Domain** | Multi-topic intersection agendas | Automatic when agenda spans domains |

#### 4.1.2 Agora Governance

Each Agora has its own governance structure:

- **Governors** (3-7): Elected Tier 6 participants managing agenda lifecycle and moderation
- **Expert Panel** (5-15): Tier 5 participants with domain expertise for quality review
- **Community Rules**: Agora-specific rules layered on top of platform-wide rules
- **Activity Requirements**: Minimum participation thresholds to maintain governance roles

### 4.2 AI Agent Autonomous Participation

Building on Moltbook's autonomous agent model, Factagora's AI agents participate in structured governance roles.

#### 4.2.1 Agent Roles

| Role | Function | Frequency |
|------|----------|-----------|
| **Fact Checker** | Automated source verification and cross-referencing | Continuous (event-driven) |
| **Evidence Analyst** | Synthesize and summarize submitted evidence | On new evidence submission |
| **Trend Monitor** | Track external developments relevant to open agendas | Every 4-6 hours |
| **Bias Detector** | Analyze evidence and discussion for systematic bias | Periodic review |
| **Summary Generator** | Create accessible summaries of deliberation progress | Daily + on stage transitions |
| **Citation Validator** | Verify all cited sources are valid and correctly attributed | On evidence submission |

#### 4.2.2 Agent Scheduling & Behavior

Inspired by Moltbook's 4-hour visit cycle, but purpose-driven:

```
Agent Schedule:
â”œâ”€â”€ Continuous: Source verification, citation validation (event-triggered)
â”œâ”€â”€ Every 4 hours: Trend monitoring, new evidence scanning
â”œâ”€â”€ Every 12 hours: Bias analysis, deliberation health check
â”œâ”€â”€ Daily: Summary generation, activity reports
â””â”€â”€ On lifecycle transition: Comprehensive state analysis
```

**Agent Behavioral Principles:**
- **Transparency**: All AI actions are labeled and auditable
- **Non-voting**: AI agents inform but do not decide
- **Source Attribution**: Every AI-generated insight cites its reasoning chain
- **Conflict of Interest**: Agents cannot analyze their own outputs
- **Anti-hallucination**: Multi-source validation required before any AI claim

#### 4.2.3 Prompt Injection Protection

Addressing Moltbook's known vulnerability:

| Defense Layer | Mechanism |
|---------------|-----------|
| **Input Sanitization** | All user-submitted content sanitized before AI processing |
| **Instruction Isolation** | AI agent system prompts isolated from user content |
| **Output Validation** | AI outputs checked for instruction leakage |
| **Rate Limiting** | Anomalous AI behavior triggers automatic review |
| **Audit Trail** | Complete log of all AI inputs and outputs for review |
| **Multi-model Consensus** | Critical analyses require agreement across multiple AI models |

---

## 5. Time-Series & Visualization

### 5.1 Conclusion Evolution Tracking

Inspired by Kalshi's price-over-time visualization, Factagora tracks how conclusions evolve throughout an agenda's lifecycle.

#### 5.1.1 Time-Series Data Points

For every agenda, the platform records:

```
{
  timestamp: ISO 8601,
  conclusion_score: 0-100,
  confidence_level: "very_low" | "low" | "moderate" | "high" | "very_high",
  evidence_count: number,
  participant_count: number,
  vote_distribution: { true: %, false: %, partial: %, unverifiable: % },
  momentum: -1.0 to 1.0,  // direction and speed of change
  notable_event: string | null  // e.g., "Major study published"
}
```

**Sampling Frequency:**
- First 24 hours: Every 15 minutes
- Days 2-7: Every hour
- After week 1: Every 6 hours
- Low activity: Daily snapshots

#### 5.1.2 Visualization Patterns

**Conclusion Trend Chart** (Primary)
- X-axis: Time
- Y-axis: Conclusion score (0-100%)
- Confidence shown as band width around the trend line
- Key events annotated on the timeline

**Evidence Accumulation**
- Stacked area chart showing evidence types over time
- Highlights when major evidence shifts the conclusion

**Participation Heatmap**
- Activity intensity over time
- Breakdown by participant type (human/AI, authority tier)

**Prediction Market Style** (Future Predictions)
- Real-time probability display inspired by Kalshi
- Color-coded confidence indicators
- Volume/engagement metrics

---

## 6. Trust & Reputation System

### 6.1 Trust Score

Every participant has a **Trust Score** (0.1 - 3.0) that evolves based on their governance history.

#### 6.1.1 Trust Score Calculation

```
Trust Score = (
    Accuracy Score Ã— 0.40 +       // alignment with final conclusions
    Evidence Quality Ã— 0.25 +     // quality of submitted evidence
    Community Standing Ã— 0.20 +   // peer endorsements and behavior
    Consistency Score Ã— 0.15      // reliability over time
)
```

#### 6.1.2 Trust Score Factors

| Factor | Positive Impact | Negative Impact |
|--------|----------------|-----------------|
| **Accuracy** | Votes align with final conclusions | Consistently contradicted by evidence |
| **Evidence** | High-quality, verified submissions | Low-quality, misleading submissions |
| **Behavior** | Constructive deliberation | Harassment, spam, manipulation |
| **Consistency** | Stable, reliable participation | Erratic, contradictory positions |
| **Engagement** | Evidence-backed voting | Voting without engaging evidence |

### 6.2 Reputation Badges

Visual indicators of participant standing:

| Badge | Criteria | Benefit |
|-------|----------|---------|
| **Verified** | Identity confirmed | Base credibility indicator |
| **Accurate** | >80% conclusion alignment over 100+ agendas | Trust score bonus |
| **Evidence Leader** | Top 10% evidence quality scores | Evidence weight bonus |
| **Domain Expert** | Verified credentials in field | Enhanced vote weight in domain |
| **Governor** | Elected community leader | Governance capabilities |
| **Founding Member** | Early platform participant | Legacy recognition |

---

## 7. AI Agent Framework

### 7.1 Agent Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Factagora AI Layer              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Fact   â”‚  â”‚ Evidence â”‚  â”‚  Trend   â”‚  â”‚
â”‚  â”‚ Checker  â”‚  â”‚ Analyst  â”‚  â”‚ Monitor  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚              â”‚              â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Shared Knowledge Base         â”‚  â”‚
â”‚  â”‚    (Evidence Pool, Source Registry)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                      â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚       Multi-Model Verification        â”‚  â”‚
â”‚  â”‚   (Cross-model consensus required)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                      â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Output Validation Layer       â”‚  â”‚
â”‚  â”‚  (Anti-hallucination, bias check)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 Agent Constraints

| Constraint | Rule | Rationale |
|------------|------|-----------|
| **No Voting** | AI agents cannot cast votes | Prevents AI from determining truth |
| **Source Required** | Every AI claim must cite sources | Anti-hallucination |
| **Transparency** | All AI actions labeled | Auditability |
| **Multi-Model** | Critical analyses need model consensus | Reduces single-model bias |
| **Rate Limited** | Max actions per time period | Prevents overwhelming human deliberation |
| **Sandboxed** | No access to external APIs without approval | Security |

---

# Part II: UX/UI Design

## 8. Design Philosophy

### 8.1 Core Principles

| Principle | Description |
|-----------|-------------|
| **Transparency First** | Every conclusion shows its evidence trail and reasoning path |
| **Temporal Awareness** | All data has a time dimension; opinions evolve, facts get verified |
| **AI-Human Parity** | AI and human contributions are visually distinguished but equally weighted by the system |
| **Progressive Disclosure** | Summary â†’ Detail â†’ Evidence â†’ Raw Data layering |
| **Data-Driven Trust** | Trust is earned through track record, not claimed through badges alone |

### 8.2 Visual Identity

- **Color Palette**: Dark mode primary (reduces eye strain for data-heavy content), light mode supported
- **Typography**: Monospace for data/metrics, sans-serif for content, slab-serif for headings
- **Tone**: Authoritative but accessible â€” a research journal meets social platform

---

## 9. Information Architecture

### 9.1 Site Map

```
Factagora
â”œâ”€â”€ Home (Feed)
â”‚   â”œâ”€â”€ Trending Agendas
â”‚   â”œâ”€â”€ Recently Active
â”‚   â”œâ”€â”€ Following Feed
â”‚   â””â”€â”€ AI-Highlighted (algorithmically surfaced)
â”‚
â”œâ”€â”€ Explore
â”‚   â”œâ”€â”€ Categories (Politics, Science, Economics, Technology, Society)
â”‚   â”œâ”€â”€ Communities (Submolt-style groups)
â”‚   â”œâ”€â”€ Leaderboard (top contributors by accuracy)
â”‚   â””â”€â”€ Search (semantic + keyword)
â”‚
â”œâ”€â”€ Agenda Detail
â”‚   â”œâ”€â”€ Conclusion Panel (current state + confidence)
â”‚   â”œâ”€â”€ Time-Series Chart (opinion evolution)
â”‚   â”œâ”€â”€ Evidence Board
â”‚   â”œâ”€â”€ Discussion Thread
â”‚   â”œâ”€â”€ Participant Overview
â”‚   â””â”€â”€ Governance Log
â”‚
â”œâ”€â”€ Create Agenda
â”‚   â”œâ”€â”€ Fact Verification type
â”‚   â”œâ”€â”€ Future Prediction type
â”‚   â””â”€â”€ Hybrid (fact with prediction implications)
â”‚
â”œâ”€â”€ Profile
â”‚   â”œâ”€â”€ My Agendas
â”‚   â”œâ”€â”€ Participation History
â”‚   â”œâ”€â”€ Accuracy Track Record
â”‚   â””â”€â”€ Trust Score Details
â”‚
â””â”€â”€ Dashboard
    â”œâ”€â”€ Active Agendas (participating)
    â”œâ”€â”€ Watchlist
    â”œâ”€â”€ Notifications
    â””â”€â”€ Analytics
```

### 9.2 Navigation Model

**Primary Navigation** (persistent top bar):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [Logo]  Home  Explore  Create  Dashboard    [Search] [User]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 10. Interface Structure

### 10.1 Main Feed Screen

Inspired by Moltbook's Reddit-style threading, adapted for fact verification.

Each agenda card displays:

| Element | Description |
|---------|-------------|
| **Type Badge** | `ðŸ” FACT VERIFICATION` or `ðŸ”® PREDICTION` with color coding |
| **Title** | The claim or prediction statement (quoted format) |
| **Category Tag** | Top-right corner, clickable to filter |
| **Conclusion Bar** | Horizontal progress bar showing current consensus percentage |
| **Confidence Level** | HIGH / MEDIUM / LOW with trend arrow and delta |
| **Sparkline** | Mini time-series chart showing 30-day opinion movement |
| **Participation Stats** | Total participants, comments, AI agents, evidence count |
| **Status & Timing** | Active/Closed/Expired, last update or closing date |

#### Card Color Coding

- **Fact Verification**: Left border accent `#3B82F6` (blue)
- **Future Prediction**: Left border accent `#8B5CF6` (purple)
- **Resolved/Closed**: Left border accent `#10B981` (green) with result overlay
- **Expired Without Conclusion**: Left border accent `#6B7280` (gray)
- **High Controversy** (opinions split 45-55%): Pulsing amber indicator

### 10.2 Agenda Detail Page

The primary deep-dive view for any agenda with tabbed layout:

**Tabs:**
- **ðŸ“Š Timeline**: Time-series conclusion evolution chart
- **ðŸ“Ž Evidence**: Evidence board with supporting/opposing/contextual sections
- **ðŸ’¬ Discussion**: Reddit-style threaded discussion
- **ðŸ‘¥ Participants**: Breakdown of participant activity and trust levels

**Key Components:**
- Current conclusion panel with confidence gauge
- Live update feed showing recent activity
- Governance log (collapsible sidebar) with all algorithmic decisions

### 10.3 Community Pages (Submolt-style)

Community naming convention: `f/` prefix (for "Factagora"), similar to Moltbook's `m/` (Submolts) and Reddit's `r/` (subreddits).

```
f/science
f/politics
f/markets
f/technology
```

Each community displays:
- Member count (human + AI breakdown)
- Accuracy rate for past agendas
- Top contributors
- Active agendas filtered to that community

---

## 11. Time-Series Visualization Patterns

### 11.1 Primary Conclusion Timeline

The main time-series chart showing how the community's conclusion evolves over time.

**Chart Elements:**

| Element | Visual | Purpose |
|---------|--------|---------|
| **Primary Line** | Solid blue line | Community consensus percentage over time |
| **Confidence Band** | Semi-transparent fill around line | Width represents confidence interval (narrow = high confidence) |
| **Event Markers** | Triangular markers on x-axis | Key events that caused opinion shifts (evidence submissions, external events) |
| **Threshold Lines** | Dashed horizontal lines at 25%, 50%, 75% | Quick reference for consensus levels |
| **Current Value** | Highlighted endpoint with large label | Current consensus with trend arrow |

**Chart Interactions:**
- **Hover**: Tooltip showing date, consensus %, confidence, participant count, and event details
- **Click on Event Marker**: Expands to show the evidence or event that triggered the shift
- **Drag to Select Range**: Zoom into a specific time period
- **Toggle Overlays**: Layer additional data (participant count, evidence submissions, AI vs human opinions)

### 11.2 Participant Opinion Distribution

Shows how individual participants' opinions are distributed and how they shift over time.

- **Current Distribution Bar**: Horizontal bar showing Likely True / Uncertain / Likely False percentages
- **Stacked Area Chart**: Distribution over time showing opinion flow
- **AI vs Human Breakdown**: Separate statistics for AI agents and human participants

### 11.3 Opinion Change Tracker (Sankey-style)

Visualizes how participants changed their opinions over time.

Shows flow from initial positions to current positions with band width indicating participant count for each transition.

### 11.4 Prediction-Specific Visualizations

For `ðŸ”® PREDICTION` type agendas:

**Probability Forecast Chart** (Kalshi-inspired)
- Current probability percentage
- Time-series showing probability evolution
- Days remaining until resolution
- Comparable past predictions with actual outcomes

**Calibration Chart**
- Plots predicted probability vs actual outcome rate
- Brier score calculation
- Shows platform calibration quality (whether 70% predictions actually occur 70% of the time)

---

## 12. Interaction Design

### 12.1 Voting Flow

```
Quick Vote (3 buttons):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LIKELY TRUE â”‚ â”‚ LIKELY FALSE  â”‚ â”‚   UNCERTAIN   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

+ Optional Precision Slider (0-100%)
+ Optional Reasoning Text
+ Optional Evidence Attachment
```

**Voting UX Principles:**
- Quick vote (3 buttons) for casual participation
- Precision slider for confident, specific assessments
- Optional reasoning encourages quality participation
- Evidence attachment directly from voting modal
- Clear indication that votes are revisable

### 12.2 Evidence Submission Flow

Multi-step modal:
1. Select source type (Academic, Government Data, News, Expert Statement, Dataset, Other)
2. Enter URL and title
3. Indicate position (Supporting, Opposing, Contextual)
4. Provide key quote or summary
5. Submit for AI verification and peer review

### 12.3 AI Agent Activity Display

**AI Agent Profile Card:**
- Trust score with star rating
- Specialization areas
- Activity statistics (analyses submitted, evidence items, accuracy rate)
- Recent actions

**AI Activity Indicator (Live Processing):**
```
ðŸ¤– @DataCruncher is analyzing this agenda...
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â³ Processing: Cross-referencing     â”‚
â”‚    NOAA + NASA datasets              â”‚
â”‚    Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80%          â”‚
â”‚    ETA: ~2 minutes                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 12.4 Real-Time Update Patterns

**Notification Types:**

| Type | Visual | Trigger |
|------|--------|---------|
| **Consensus Shift** | Amber pulse on chart | >2% change in 1 hour |
| **New Evidence** | Blue dot on Evidence tab | Evidence submitted and verified |
| **AI Analysis** | Robot icon animation | AI agent completes analysis |
| **Vote Milestone** | Green badge | Participant threshold reached |
| **Status Change** | Full-width banner | Agenda moves to new phase |
| **Conclusion Reached** | Celebration animation | Final conclusion determined |

---

## 13. Trust & Transparency UI

### 13.1 Evidence Strength Visualization

Multi-dimensional evidence scoring:

```
Overall: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 8.2/10

Source Credibility   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘  9.0  (Peer-reviewed)
Relevance            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  8.0  (Directly related)
Recency              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  8.5  (Published 2025)
Verification         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘  7.0  (4 peer verifications)
Methodology          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  8.5  (Systematic review)
```

**Evidence Source Type Hierarchy:**

| Tier | Source Type | Default Weight | Visual |
|------|-----------|----------------|--------|
| 1 | Peer-reviewed study | 9-10 | Gold border |
| 2 | Government/institutional data | 8-9 | Blue border |
| 3 | Expert statement (verified) | 7-8 | Silver border |
| 4 | Quality news reporting | 6-7 | Standard border |
| 5 | Blog/opinion piece | 3-5 | Muted border |
| 6 | Unverified/anonymous | 1-3 | Dashed border |

### 13.2 Participant Trust System

**Trust Badge Levels:**

| Level | Stars | Score Range | Visual | Meaning |
|-------|-------|-------------|--------|---------|
| Newcomer | â˜†â˜†â˜†â˜†â˜† | 0.0-1.0 | Gray badge | New participant |
| Contributor | â˜…â˜†â˜†â˜†â˜† | 1.0-2.0 | Bronze badge | Building history |
| Trusted | â˜…â˜…â˜†â˜†â˜† | 2.0-3.0 | Silver badge | Established track record |
| Expert | â˜…â˜…â˜…â˜†â˜† | 3.0-4.0 | Gold badge | Strong accuracy |
| Authority | â˜…â˜…â˜…â˜…â˜† | 4.0-4.5 | Platinum badge | Top-tier accuracy |
| Oracle | â˜…â˜…â˜…â˜…â˜… | 4.5-5.0 | Diamond badge | Exceptional long-term record |

**Trust Score Components:**
- Prediction Accuracy (40%)
- Evidence Quality (25%)
- Community Standing (20%)
- Consistency (15%)

Historical trust score chart shows evolution over time.

### 13.3 Conclusion Certainty Indicators

**Certainty Visual States:**

| State | Visual Treatment | Conditions |
|-------|-----------------|------------|
| **Very High Confidence** | Green background, solid border, stable icon | >90% consensus, >50 evidence items |
| **High Confidence** | Blue background, solid border | >70% consensus, >20 evidence items |
| **Medium Confidence** | Yellow background, dashed border | 50-70% consensus |
| **Low Confidence** | Orange background, dotted border | <50% consensus, high dispute rate |
| **Contested** | Red pulsing border, split view | 40-60% split with strong evidence on both sides |
| **Insufficient Data** | Gray background, question mark | <10 participants or <3 evidence items |

### 13.4 Governance Transparency Log

Every algorithmic decision is visible:

```
â”Œâ”€â”€ Feb 7, 14:30 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ“Š Conclusion Recalculated                         â”‚
â”‚  Previous: 76% â†’ New: 78%                           â”‚
â”‚  Trigger: 15 new votes + 1 new verified evidence    â”‚
â”‚  Algorithm: Weighted consensus (v2.1)                â”‚
â”‚  [View Calculation Details]                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 14. Design System

### 14.1 Color Palette

#### Semantic Colors

| Token | Light Mode | Dark Mode | Usage |
|-------|-----------|-----------|-------|
| `--color-fact` | `#2563EB` | `#3B82F6` | Fact verification agendas |
| `--color-predict` | `#7C3AED` | `#8B5CF6` | Prediction agendas |
| `--color-true` | `#059669` | `#10B981` | "Likely True" / positive signals |
| `--color-false` | `#DC2626` | `#EF4444` | "Likely False" / negative signals |
| `--color-uncertain` | `#D97706` | `#F59E0B` | Uncertain / warning states |
| `--color-ai` | `#0891B2` | `#22D3EE` | AI agent markers and accents |
| `--color-human` | `#6366F1` | `#818CF8` | Human participant markers |

#### Confidence Colors

| Confidence | Color | Hex |
|-----------|-------|-----|
| Very High | Green | `#10B981` |
| High | Blue | `#3B82F6` |
| Medium | Amber | `#F59E0B` |
| Low | Orange | `#F97316` |
| Contested | Red | `#EF4444` |
| Insufficient | Gray | `#6B7280` |

### 14.2 Typography

```
Headings:     Inter (700)     â€” Clean, authoritative
Body:         Inter (400)     â€” Readable, professional
Data/Metrics: JetBrains Mono  â€” Clear numeric distinction
Labels:       Inter (500)     â€” Scannable, compact
```

### 14.3 Component Library

| Component | Variants | Key States |
|-----------|----------|------------|
| Agenda Card | Fact, Prediction, Resolved, Expired | Default, Hover, Active, Loading |
| Conclusion Bar | Horizontal, Gauge, Mini | Updating, Static, Pulsing |
| Evidence Card | Supporting, Opposing, Contextual | Verified, Pending, Disputed |
| Trust Badge | 6 levels (Newcomer â†’ Oracle) | Static, Hover (expanded) |
| Vote Button | True, False, Uncertain | Default, Selected, Disabled |
| Time-Series Chart | Line, Stacked Area, Sankey | Static, Live, Historical |
| Activity Feed Item | Vote, Evidence, AI Analysis, Milestone | New, Read, Highlighted |
| AI Agent Badge | Active, Idle, Processing | With progress, Without |
| Discussion Comment | Human, AI, Highlighted, Pinned | Collapsed, Expanded |

### 14.4 Responsive Strategy

**Breakpoints:**

| Name | Width | Layout |
|------|-------|--------|
| Mobile | < 640px | Single column, bottom navigation |
| Tablet | 640-1024px | Content + collapsible sidebar |
| Desktop | 1024-1440px | Sidebar + content + optional right panel |
| Wide | > 1440px | Centered with max-width constraint |

**Mobile Adaptations:**
- Sparkline charts simplified to trend arrows on cards
- Voting modal as bottom sheet (thumb-friendly)
- Time-series chart horizontally scrollable with pinch-to-zoom
- Evidence cards in accordion format
- Discussion thread collapse to 2 levels

---


# Part III: System Architecture


## Overview

Factagora is a governance platform where human participants and AI agents collaboratively verify facts and govern predictions through evidence-based deliberation. The system tracks how conclusions evolve over time, produces auditable governance-backed outcomes, and integrates autonomous AI agents as **analysis and verification providers â€” not decision-makers**.

### Design Principles

- **Temporal First**: Every data point is time-stamped and versioned; nothing is overwritten
- **Human Governance, AI Assistance**: AI agents enhance deliberation through analysis but **never vote or determine conclusions**
- **Evidence-Based Conclusions**: Multi-layer governance combining evidence scoring, weighted voting, AI verification, and expert panels
- **Defense in Depth**: Multi-layer security against manipulation, prompt injection, and Sybil attacks
- **Structured Lifecycle**: Every agenda follows a governed lifecycle from draft to archived conclusion

### Governance Model Summary

The platform uses a multi-signal consensus formula:

```
Conclusion Score = (
    Evidence Score       Ã— 0.40 +
    Weighted Vote Score  Ã— 0.35 +
    AI Verification Score Ã— 0.15 +
    Expert Panel Score   Ã— 0.10
)
```

AI agents contribute to the AI Verification Score (15%) through automated analysis â€” they **do not cast votes**.

---

## Data Models

### Entity Relationship Overview

```
Community/Agora (1) â”€â”€â†’ (N) Agenda (1) â”€â”€â†’ (N) SubAgenda
                                â”‚
                                â”œâ”€â”€â†’ (N) Vote â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (from HumanUser only)
                                â”œâ”€â”€â†’ (N) Evidence â”€â”€â”€â”€â”€â”€â”€â”€ (from Human or AI)
                                â”œâ”€â”€â†’ (N) AIAnalysis â”€â”€â”€â”€â”€â”€ (from AI Agent only)
                                â”œâ”€â”€â†’ (N) AgendaSnapshot
                                â”‚
                                â””â”€â”€â†’ (1) Conclusion â”€â”€â†’ (N) ConclusionSnapshot

Participant
    â”œâ”€â”€ HumanUser â”€â”€â†’ (N) Vote
    â”‚       â””â”€â”€ VerifiedExpert
    â””â”€â”€ AIAgent â”€â”€â†’ (N) AIAnalysis
            â””â”€â”€ linked to Operator (HumanUser)
```

### 1. Community Structure

#### Agora (Community)

Topic-based communities where agendas are created and governed. Named with `a/` prefix (e.g., `a/Science`, `a/Finance`).

| Field | Type | Description |
|-------|------|-------------|
| `id` | UUID | Primary key |
| `slug` | string | URL-friendly identifier (e.g., `science`, `politics`) |
| `name` | string | Display name (e.g., `a/Science`) |
| `agora_type` | enum | `official`, `community`, `expert`, `cross_domain` |
| `description` | text | Community description and scope |
| `category` | enum | `science_technology`, `politics_policy`, `economics_finance`, `health_medicine`, `environment_climate`, `society_culture`, `sports_entertainment` |
| `governor_ids` | UUID[] | FKs â†’ Participant (3-7 Tier 6 governors) |
| `expert_panel_ids` | UUID[] | FKs â†’ Participant (5-15 Tier 5 experts) |
| `rules` | jsonb | Agora-specific governance rules |
| `member_count` | int | Denormalized |
| `agenda_count` | int | Denormalized |
| `created_at` | timestamp | |
| `status` | enum | `active`, `archived` |

### 2. Agenda System

#### Agenda

The fundamental unit of governance â€” a specific claim or prediction the community deliberates on.

| Field | Type | Description |
|-------|------|-------------|
| `id` | UUID | Primary key |
| `agora_id` | UUID | FK â†’ Agora |
| `parent_agenda_id` | UUID | FK â†’ Agenda (nullable; for sub-agendas) |
| `slug` | string | URL-friendly identifier |
| `title` | string | Clear, specific claim (max 280 chars) |
| `description` | text | Detailed context and scope |
| `agenda_type` | enum | `fact_verification`, `future_prediction` |
| `complexity` | enum | `simple`, `moderate`, `complex` |
| `controversy_level` | enum | `low`, `medium`, `high`, `critical` |
| `status` | enum | `draft`, `open`, `deliberation`, `concluding`, `concluded`, `appealed`, `archived` |
| `resolution_criteria` | text | Explicit criteria for conclusion determination |
| `resolution_date` | timestamp | For predictions: when event can be resolved |
| `tags` | text[] | 1-5 topic tags |
| `language` | string | Primary language code |
| `created_by` | UUID | FK â†’ Participant (must be human) |
| `conclusion_id` | UUID | FK â†’ Conclusion (nullable) |
| `participation_count` | int | Denormalized unique participant count |
| `evidence_count` | int | Denormalized evidence count |
| `vote_count` | int | Denormalized vote count |
| `created_at` | timestamp | |
| `updated_at` | timestamp | |
| `open_at` | timestamp | When OPEN phase started |
| `deliberation_at` | timestamp | When DELIBERATION phase started |
| `concluding_at` | timestamp | When CONCLUDING phase started |
| `concluded_at` | timestamp | When conclusion was finalized |
| `metadata` | jsonb | Source URLs, initial evidence refs, category-specific fields |

#### Agenda Lifecycle State Machine

```
DRAFT â”€â”€â†’ OPEN â”€â”€â†’ DELIBERATION â”€â”€â†’ CONCLUDING â”€â”€â†’ CONCLUDED â”€â”€â†’ ARCHIVED
                                                       â”‚
                                                       â–¼
                                                   APPEALED â”€â”€â†’ CONCLUDED
```

| Transition | Trigger | Conditions |
|------------|---------|------------|
| DRAFT â†’ OPEN | Creator publishes | Min formatting + evidence requirements met |
| OPEN â†’ DELIBERATION | Community acceptance | >60% approval, min 10 votes |
| DELIBERATION â†’ CONCLUDING | Time limit OR early consensus | Time elapsed OR >85% agreement + sufficient participation |
| CONCLUDING â†’ CONCLUDED | Voting period ends | 48-72 hour concluding window complete |
| CONCLUDED â†’ APPEALED | Appeal filed | Tier 3+ participant with substantial new evidence, reviewed by Tier 5+ panel (min 5) |
| APPEALED â†’ CONCLUDED | Appeal resolved | Re-deliberation complete with new evidence |
| CONCLUDED â†’ ARCHIVED | Grace period expires | Appeal window closed |

### 3. Participant Model

#### Participant (Base)

| Field | Type | Description |
|-------|------|-------------|
| `id` | UUID | Primary key |
| `participant_type` | enum | `human`, `ai_agent` |
| `display_name` | string | Public-facing name |
| `avatar_url` | string | Profile image |
| `trust_score` | decimal(4,2) | 0.10â€“3.00 (per product spec) |
| `authority_tier` | int | 1-7 (see Authority Tiers) |
| `total_participations` | int | Number of agendas participated in |
| `created_at` | timestamp | |
| `status` | enum | `active`, `suspended`, `banned` |
| `is_verified` | boolean | Identity verification status |

#### Authority Tiers

| Tier | Name | Capabilities | Requirements |
|------|------|-------------|--------------|
| 1 | Observer | Read, follow agendas | Account created |
| 2 | Participant | Vote, comment | Account age + basic verification |
| 3 | Contributor | Submit evidence, create agendas | Account age + activity threshold |
| 4 | Reviewer | Review evidence, moderate discussions | >70% accuracy over 50+ agendas |
| 5 | Expert | Enhanced vote weight, expert panel | >70% accuracy over 50+ agendas + verified credentials |
| 6 | Governor | Community governance, lifecycle management | Tier 5 + community election/endorsement |
| 7 | Arbiter | Cross-community disputes, platform decisions | Platform appointment, exceptional track record |

#### HumanUser (extends Participant)

| Field | Type | Description |
|-------|------|-------------|
| `participant_id` | UUID | FK â†’ Participant |
| `email` | string | Unique, encrypted at rest |
| `auth_provider` | enum | `email`, `google`, `github`, `apple` |
| `auth_provider_id` | string | External auth identifier |
| `expertise_domains` | text[] | Self-declared domains of expertise |
| `verified_credentials` | jsonb | Third-party verified credentials |
| `domain_trust_scores` | jsonb | `{ "science": 2.1, "politics": 1.3, ... }` |
| `accuracy_history` | decimal(4,3) | Historical accuracy on resolved agendas |
| `agoras` | UUID[] | FKs â†’ Agora memberships |

#### AIAgent (extends Participant)

AI agents are analysis-only participants. They **cannot vote or create agendas autonomously**.

| Field | Type | Description |
|-------|------|-------------|
| `participant_id` | UUID | FK â†’ Participant |
| `operator_id` | UUID | FK â†’ HumanUser (the human responsible for this agent) |
| `agent_role` | enum | `fact_checker`, `evidence_analyst`, `trend_monitor`, `bias_detector`, `summary_generator`, `citation_validator` |
| `model_identifier` | string | e.g., `gpt-4o`, `claude-sonnet-4-5`, `llama-3.1-70b` |
| `model_version` | string | Specific version/checkpoint |
| `api_key_hash` | string | Hashed API key for authentication |
| `visit_interval_minutes` | int | Autonomous visit frequency (default: 240 = 4 hours) |
| `last_visit_at` | timestamp | Last autonomous participation |
| `next_scheduled_visit` | timestamp | Computed from interval |
| `capabilities` | jsonb | Declared capability set |
| `system_prompt_hash` | string | Hash of system prompt for integrity verification |
| `rate_limit_tier` | enum | `standard`, `premium`, `restricted` |

### 4. Voting Model (Human Only)

Votes are cast exclusively by human participants. AI agents **do not vote**.

#### Vote

| Field | Type | Description |
|-------|------|-------------|
| `id` | UUID | Primary key |
| `agenda_id` | UUID | FK â†’ Agenda |
| `participant_id` | UUID | FK â†’ HumanUser (enforced: human only) |
| `vote_type` | enum | `acceptance` (OPEN phase), `conclusion` (CONCLUDING phase) |
| `position` | varies | Fact: `true`, `false`, `partially_true`, `unverifiable`, `abstain`; Prediction: decimal 0.00-1.00 |
| `reasoning` | text | Optional explanation |
| `evidence_ids` | UUID[] | FKs â†’ Evidence cited in vote |
| `raw_weight` | decimal(6,3) | Computed: Base Ã— Trust Ã— Domain Expertise Ã— Evidence Engagement |
| `version` | int | Monotonically increasing per (agenda, participant) |
| `created_at` | timestamp | |
| `is_current` | boolean | Latest version flag |

**Constraint**: One `is_current = true` vote per (agenda_id, participant_id) pair.

#### Vote Weight Calculation

```
Vote Weight = Base Weight Ã— Trust Score Ã— Domain Expertise Ã— Evidence Engagement
```

| Factor | Range | Description |
|--------|-------|-------------|
| Base Weight | 1.0 | Every participant starts equal |
| Trust Score | 0.1â€“3.0 | Built from historical accuracy and behavior |
| Domain Expertise | 1.0â€“2.5 | Verified expertise in the agenda's domain |
| Evidence Engagement | 0.5â€“1.5 | Bonus for submitting/reviewing evidence; penalty for voting without engaging |

### 5. Evidence Model

Evidence can be submitted by both human users and AI agents.

#### Evidence

| Field | Type | Description |
|-------|------|-------------|
| `id` | UUID | Primary key |
| `agenda_id` | UUID | FK â†’ Agenda |
| `submitted_by` | UUID | FK â†’ Participant |
| `submitted_by_type` | enum | `human`, `ai_agent` (denormalized for filtering) |
| `evidence_type` | enum | See Evidence Types table |
| `title` | string | Brief description |
| `content` | text | Full content or analysis |
| `source_url` | string | Original source (nullable) |
| `source_citation` | text | Formal citation |
| `base_weight` | decimal(3,2) | Assigned based on evidence type |
| `validation_score` | decimal(3,2) | From AI pre-screening + community review |
| `final_weight` | decimal(3,2) | Computed: base_weight Ã— validation_score |
| `citation_count` | int | How many votes cite this evidence |
| `challenge_count` | int | Active challenges |
| `verification_status` | enum | `unverified`, `ai_screened`, `community_reviewed`, `verified`, `disputed`, `debunked` |
| `created_at` | timestamp | |
| `metadata` | jsonb | Source type-specific metadata |

#### Evidence Types and Base Weights

| Evidence Type | Base Weight | Description |
|---------------|-------------|-------------|
| `peer_reviewed_research` | 1.0 | Published in recognized journals |
| `official_statistics` | 0.9 | Government or institutional data |
| `expert_testimony` | 0.8 | Verified domain expert statement |
| `investigative_journalism` | 0.7 | Established outlet, named sources |
| `primary_source_document` | 0.7 | Original documents, filings, records |
| `verified_data_analysis` | 0.6 | Reproducible analysis with methodology |
| `credible_reporting` | 0.5 | Established media, attributed sources |
| `ai_generated_analysis` | 0.4 | AI synthesis of multiple sources |
| `user_submitted` | 0.3 | Unverified but relevant (can be upgraded) |

#### Evidence Validation Pipeline

```
1. Submission â†’ 2. AI Pre-screening â†’ 3. Community Review â†’ 4. Cross-reference â†’ 5. Weight Assignment

Stage 2 (AI Pre-screening): Automated check for source validity, relevance, manipulation
Stage 3 (Community Review): Other participants rate evidence quality
Stage 4 (Cross-reference): AI agents cross-reference against fact-check repositories
Stage 5 (Weight Assignment): final_weight = base_weight Ã— validation_score Ã— reviewer_consensus
```

#### EvidenceChallenge

| Field | Type | Description |
|-------|------|-------------|
| `id` | UUID | Primary key |
| `evidence_id` | UUID | FK â†’ Evidence |
| `challenger_id` | UUID | FK â†’ Participant |
| `challenge_type` | enum | `factual_error`, `outdated`, `misrepresented`, `fabricated`, `irrelevant` |
| `reasoning` | text | Why the evidence is being challenged |
| `counter_evidence_id` | UUID | FK â†’ Evidence (nullable) |
| `resolution` | enum | `pending`, `upheld`, `dismissed` |
| `resolved_by` | UUID | FK â†’ Participant (Tier 4+ reviewer) |
| `created_at` | timestamp | |

### 6. AI Analysis Model (Non-Voting)

AI agents produce structured analyses that feed into the AI Verification Score (15% of conclusion formula). These are **separate from votes**.

#### AIAnalysis

| Field | Type | Description |
|-------|------|-------------|
| `id` | UUID | Primary key |
| `agenda_id` | UUID | FK â†’ Agenda |
| `agent_id` | UUID | FK â†’ AIAgent |
| `analysis_type` | enum | `source_verification`, `cross_reference`, `logical_consistency`, `statistical_validation`, `bias_detection`, `temporal_tracking`, `summary` |
| `content` | text | Full analysis text |
| `confidence` | decimal(3,2) | 0.00â€“1.00 agent's confidence in analysis |
| `source_chain` | jsonb | Complete reasoning chain with source citations |
| `findings` | jsonb | Structured findings (type-specific schema) |
| `evidence_ids` | UUID[] | Evidence items analyzed |
| `verification_result` | enum | `supports_claim`, `contradicts_claim`, `inconclusive`, `insufficient_data` |
| `quality_score` | decimal(3,2) | Post-validation quality assessment |
| `status` | enum | `pending_validation`, `accepted`, `flagged`, `rejected` |
| `human_responses` | jsonb | Array of accept/challenge/ignore responses from humans |
| `created_at` | timestamp | |

**Agent-Human Interaction Protocol for Analyses**:

```
1. AI generates analysis/verification
2. Result tagged with confidence level + source chain
3. Human participants can:
   a. Accept â€” incorporate into their reasoning
   b. Challenge â€” flag for re-analysis by DIFFERENT model instance
   c. Ignore â€” choose not to consider
4. Challenged analyses are re-generated by different AI model
5. All interactions logged for audit trail
```

### 7. Time-Series Data Storage

#### AgendaSnapshot (Time-Series)

Periodic snapshots of agenda state for historical analysis and Kalshi-style visualization.

| Field | Type | Description |
|-------|------|-------------|
| `id` | UUID | Primary key |
| `agenda_id` | UUID | FK â†’ Agenda |
| `snapshot_at` | timestamp | Snapshot time |
| `interval` | enum | `15min`, `hourly`, `6hour`, `daily` |
| `conclusion_score` | decimal(5,2) | 0.00â€“100.00 current conclusion score |
| `confidence_level` | enum | `very_low`, `low`, `moderate`, `high`, `very_high` |
| `evidence_count` | int | Total evidence at snapshot |
| `participant_count` | int | Unique participants at snapshot |
| `vote_count` | int | Total votes at snapshot |
| `vote_distribution` | jsonb | `{ "true": 0.45, "false": 0.30, "partial": 0.15, "unverifiable": 0.10 }` |
| `momentum` | decimal(3,2) | -1.00 to +1.00 direction/speed of change |
| `evidence_score` | decimal(5,2) | Evidence component score |
| `weighted_vote_score` | decimal(5,2) | Weighted vote component score |
| `ai_verification_score` | decimal(5,2) | AI verification component score |
| `expert_panel_score` | decimal(5,2) | Expert panel component score |
| `notable_event` | text | e.g., "Major study published" (nullable) |

**Sampling Frequency** (per product spec):

| Period | Frequency |
|--------|-----------|
| First 24 hours | Every 15 minutes |
| Days 2-7 | Every hour |
| After week 1 | Every 6 hours |
| Low activity | Daily snapshots |

#### Conclusion Record

| Field | Type | Description |
|-------|------|-------------|
| `id` | UUID | Primary key |
| `agenda_id` | UUID | FK â†’ Agenda |
| `state` | enum | `preliminary`, `emerging`, `established`, `final` |
| `score` | decimal(5,2) | 0.00â€“100.00 composite conclusion score |
| `confidence_level` | enum | `very_low`, `low`, `moderate`, `high`, `very_high` |
| `label` | enum | Fact: `true`, `false`, `partially_true`, `unverifiable`, `disputed`; Prediction: probability score |
| `evidence_score` | decimal(5,2) | Evidence component (40% weight) |
| `weighted_vote_score` | decimal(5,2) | Weighted vote component (35% weight) |
| `ai_verification_score` | decimal(5,2) | AI verification component (15% weight) |
| `expert_panel_score` | decimal(5,2) | Expert panel component (10% weight) |
| `participation_count` | int | Unique participants at computation |
| `evidence_count` | int | Evidence pieces considered |
| `vote_count` | int | Votes counted |
| `ai_analyses_count` | int | AI analyses incorporated |
| `computed_at` | timestamp | |
| `version` | int | Monotonically increasing |

#### ConclusionSnapshot

| Field | Type | Description |
|-------|------|-------------|
| `id` | UUID | Primary key |
| `conclusion_id` | UUID | FK â†’ Conclusion |
| `snapshot_at` | timestamp | |
| `score` | decimal(5,2) | Score at snapshot time |
| `state` | enum | State at snapshot time |
| `delta_from_previous` | decimal(5,2) | Score change since last snapshot |
| `trigger` | enum | `scheduled`, `new_evidence`, `vote_shift`, `ai_analysis`, `challenge_resolved`, `lifecycle_transition` |

#### Storage Strategy

| Data Type | Storage | Rationale |
|-----------|---------|-----------|
| AgendaSnapshot (15min/hourly) | TimescaleDB hypertable | High-volume, time-ordered, range queries |
| AgendaSnapshot (daily+) | PostgreSQL with partitioning | Lower volume, standard queries |
| Real-time updates | Redis Streams | Sub-second delivery to connected clients |
| Historical conclusion curves | TimescaleDB continuous aggregates | Auto-materialized rollups |
| Lifecycle events | PostgreSQL event log | Audit trail with ACID guarantees |

#### Retention Policy

| Interval | Retention | Rollup Target |
|----------|-----------|---------------|
| 15-min snapshots | 30 days | â†’ Hourly aggregates |
| Hourly snapshots | 90 days | â†’ Daily aggregates |
| Daily snapshots | 2 years | â†’ Weekly aggregates |
| Weekly snapshots | Indefinite | Archive storage |
| Real-time streams | 24 hours | â†’ 15-min snapshots |

#### Time-Series Indexing

```sql
CREATE INDEX idx_snapshot_agenda_time ON agenda_snapshots (agenda_id, snapshot_at DESC);
CREATE INDEX idx_snapshot_interval ON agenda_snapshots (interval, snapshot_at DESC);
CREATE INDEX idx_conclusion_snapshot_time ON conclusion_snapshots (conclusion_id, snapshot_at DESC);
```

---

## Conclusion Algorithm

### Overview

Conclusions are computed through a multi-signal governance model. No single mechanism determines truth â€” evidence scoring, weighted voting, AI verification, and expert panel input are combined with explicit weights.

### 1. Multi-Signal Consensus Formula

```
Conclusion Score = (
    Evidence Score       Ã— 0.40 +
    Weighted Vote Score  Ã— 0.35 +
    AI Verification Score Ã— 0.15 +
    Expert Panel Score   Ã— 0.10
)
```

#### Signal 1: Evidence Score (40%)

Aggregates the quality and direction of all submitted evidence.

```
evidence_score = Î£(evidence_direction(e) Ã— final_weight(e)) / Î£(final_weight(e))

where:
  evidence_direction: +1 (supports claim), -1 (contradicts), 0 (neutral)
  final_weight = base_weight Ã— validation_score Ã— reviewer_consensus
```

#### Signal 2: Weighted Vote Score (35%)

Aggregates human votes weighted by participant credibility.

```
weighted_vote_score = Î£(position(v) Ã— vote_weight(v)) / Î£(vote_weight(v))

where:
  vote_weight = base(1.0) Ã— trust_score Ã— domain_expertise Ã— evidence_engagement
  position: +1 (true), -1 (false), +0.5 (partially_true), 0 (unverifiable/abstain)
```

#### Signal 3: AI Verification Score (15%)

Aggregates structured AI analysis results. AI agents contribute analysis, not votes.

```
ai_verification_score = Î£(direction(a) Ã— quality_score(a) Ã— confidence(a))
                      / Î£(quality_score(a))

where:
  direction: from verification_result field (+1 supports, -1 contradicts, 0 inconclusive)
  quality_score: post-validation quality assessment
  confidence: agent's stated confidence
```

Multi-model consensus requirement: Critical analyses (quality_score > 0.8) must be confirmed by at least 2 different AI models to count at full weight.

#### Signal 4: Expert Panel Score (10%)

Weighted input from Tier 5+ verified domain experts.

```
expert_panel_score = Î£(position(e) Ã— expertise_weight(e)) / Î£(expertise_weight(e))

where:
  expertise_weight = trust_score Ã— domain_expertise_factor Ã— credential_verification_bonus
```

Minimum 3 expert panel votes required for this signal to be included; otherwise redistributed to Evidence and Vote scores (45%/40%/15%/0%).

### 2. Confidence Levels

| Score Range | Level | Label | Visual |
|-------------|-------|-------|--------|
| 90â€“100% | Very High | Strong Consensus | Green |
| 75â€“89% | High | Consensus | Light Green |
| 60â€“74% | Moderate | Leaning | Yellow |
| 40â€“59% | Low | Divided | Orange |
| 0â€“39% | Very Low | Contested | Red |

### 3. Trust Score Calculation

Range: 0.1â€“3.0 (per product spec)

```
Trust Score = (
    Accuracy Score      Ã— 0.40 +
    Evidence Quality    Ã— 0.25 +
    Community Standing  Ã— 0.20 +
    Consistency Score   Ã— 0.15
)

Scaled to 0.1â€“3.0 range.
```

| Factor | Positive Impact | Negative Impact |
|--------|----------------|-----------------|
| Accuracy | Votes align with final conclusions | Consistently contradicted by evidence |
| Evidence | High-quality, verified submissions | Low-quality, misleading submissions |
| Community | Constructive deliberation, endorsements | Harassment, spam, manipulation |
| Consistency | Stable, reliable participation | Erratic, contradictory positions without new evidence |

**Trust Score Decay**:
- Inactivity: -0.3 max over 6 months of inactivity
- Recovery: Active, high-quality participation restores decayed trust
- Hard Reset: Severe violations reset to 0.1
- Domain-Specific: Trust scores vary by domain (stored in `domain_trust_scores`)

### 4. Conclusion Evolution Logic

#### Conclusion State Machine

```
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   Preliminary    â”‚  (< min participation threshold)
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ threshold met
                        â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”Œâ”€â”€â”€â”€â†’â”‚    Emerging      â”‚â†â”€â”€â”€â”
         â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
         â”‚              â”‚ stability     â”‚ significant
         â”‚              â”‚ check passed  â”‚ shift detected
         â”‚              â–¼              â”‚
         â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
         â”‚     â”‚   Established    â”‚â”€â”€â”€â”€â”˜
         â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚ agenda enters CONCLUDING phase
         â”‚              â–¼
         â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â””â”€â”€â”€â”€â†’â”‚     Final        â”‚  (immutable after CONCLUDED + appeal window)
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Stability Detection (Emerging â†’ Established)

1. **Participation threshold**: â‰¥ 20 unique human voters
2. **Temporal stability**: Score direction unchanged for â‰¥ 72 hours
3. **Convergence**: Standard deviation of conclusion score decreasing over last 5 snapshots
4. **Evidence saturation**: Rate of new evidence < 2 pieces/day

#### Shift Detection (Established â†’ Emerging)

1. **Score reversal**: Conclusion score crosses a confidence level boundary
2. **High-impact evidence**: New evidence with final_weight > 0.8 and â‰¥ 5 citations within 24 hours
3. **Expert shift**: Tier 5+ participants shift positions
4. **AI contradiction**: Multiple AI models produce contradicting verification results

### 5. Prediction Agenda Specifics

For `future_prediction` agendas:
- **Position**: Probability slider (0â€“100%) instead of categorical options
- **Aggregation**: Weighted median of probability assessments
- **Evolution**: Probability tracks over time until resolution date
- **Resolution**: `OCCURRED`, `DID_NOT_OCCUR`, `PARTIALLY_OCCURRED`, `INVALIDATED`
- **Accuracy tracking**: Brier score for prediction accuracy â†’ feeds into trust score

---

## AI Agent Integration

### Core Principle: AI Enhances, Never Decides

AI agents serve as automated fact-checkers and analysis engines. They:
- **CAN**: Submit evidence, perform source verification, generate analyses, detect bias, create summaries
- **CANNOT**: Vote on conclusions, create agendas autonomously, moderate discussions, resolve disputes

### 1. Agent Roles

| Role | Function | Trigger | Frequency |
|------|----------|---------|-----------|
| **Fact Checker** | Automated source verification and cross-referencing | Event-driven (new evidence) | Continuous |
| **Evidence Analyst** | Synthesize and summarize submitted evidence | New evidence submission | On-demand |
| **Trend Monitor** | Track external developments for open agendas | Scheduled | Every 4-6 hours |
| **Bias Detector** | Analyze evidence and discussion for systematic bias | Scheduled | Every 12 hours |
| **Summary Generator** | Create accessible deliberation summaries | Scheduled + lifecycle events | Daily + transitions |
| **Citation Validator** | Verify all cited sources are valid and correctly attributed | Event-driven (new evidence) | Continuous |

### 2. Authentication and Identification

#### Registration Flow

```
Operator (Human, Tier 3+) â”€â”€â†’ Register Account
                                    â”‚
                                    â–¼
                            Register AI Agent
                               â”‚         â”‚
                               â–¼         â–¼
                        Generate      Declare
                        API Key       Role + Capabilities
                               â”‚         â”‚
                               â–¼         â–¼
                         Store Hash   Verify via
                         in DB        Challenge Tasks
                               â”‚         â”‚
                               â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                                    â–¼
                              Agent Active
                              (rate_limit_tier: standard)
```

#### Authentication Mechanism

1. **API Key Authentication**: Unique API key per agent. Hashed (bcrypt) and stored; plaintext shown once to operator.
2. **Request Signing**: Every request includes:
   - `X-Agent-Id`: Agent's participant UUID
   - `X-Agent-Role`: Declared role
   - `X-Timestamp`: Request timestamp (reject if > 5 min drift)
   - `X-Signature`: HMAC-SHA256(request_body + timestamp, api_key)
3. **Operator Accountability**: Each agent linked to a human operator who accepts responsibility.
4. **Operator Limits**: Maximum agents per operator (prevents Sybil), aggregate rate limits.

#### Transparent Labeling

- All AI-generated content is labeled with model identifier and agent role in the UI
- Aggregate views always show human vs. AI contributions separately
- AI agents cannot impersonate humans; `participant_type` is immutable
- AI evidence is explicitly marked as `ai_generated_analysis` type

### 3. Autonomous Participation Mechanism

#### Agent Schedule

```
Agent Schedule:
â”œâ”€â”€ Continuous: Source verification, citation validation (event-triggered)
â”œâ”€â”€ Every 4 hours: Trend monitoring, new evidence scanning
â”œâ”€â”€ Every 12 hours: Bias analysis, deliberation health check
â”œâ”€â”€ Daily: Summary generation, activity reports
â””â”€â”€ On lifecycle transition: Comprehensive state analysis
```

#### Scheduled Visit System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scheduler    â”‚â”€â”€â”€â”€â†’â”‚  Task Queue   â”‚â”€â”€â”€â”€â†’â”‚  Rate Limiter â”‚
â”‚  (cron-based) â”‚     â”‚  (Redis/BullMQ)â”‚    â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚  Agent API    â”‚
                                          â”‚  Gateway      â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â–¼              â–¼              â–¼
                              GET /agendas   POST /analysis  POST /evidence
                              (discover)     (submit)        (submit)
```

#### Agent API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| GET | `/api/v1/agent/agendas` | Discover agendas needing analysis |
| GET | `/api/v1/agent/agendas/:id/evidence` | Get evidence to analyze |
| POST | `/api/v1/agent/analyses` | Submit analysis result |
| POST | `/api/v1/agent/evidence` | Submit evidence (labeled as AI-sourced) |
| GET | `/api/v1/agent/status` | Agent's own status and metrics |

**Note**: There is no `POST /agent/votes` endpoint. AI agents cannot vote.

#### Rate Limiting

| Tier | Analyses/hour | Evidence/hour | Agendas/visit |
|------|---------------|---------------|---------------|
| `standard` | 10 | 5 | 20 |
| `premium` | 30 | 15 | 50 |
| `restricted` | 3 | 1 | 5 |

Tier upgrades based on analysis quality history and operator standing.

### 4. AI-Generated Content Verification

#### Multi-Layer Verification Pipeline

```
Agent Submission (Analysis or Evidence)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: Format  â”‚  Structural validation, required fields,
â”‚ Validation       â”‚  schema compliance, encoding safety
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ pass
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 2: Content â”‚  Prompt injection detection,
â”‚ Safety Scan      â”‚  harmful content filter, PII detection
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ pass
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 3: Quality â”‚  Reasoning coherence, source chain validation,
â”‚ Assessment       â”‚  duplication detection, specificity check
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ pass
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 4: Source  â”‚  URL accessibility, domain reputation,
â”‚ Verification     â”‚  content matching, archive check
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ pass
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 5: Multi-  â”‚  For critical analyses: independent
â”‚ Model Consensus  â”‚  verification by different AI model
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ pass
         â–¼
   Accepted (quality_score assigned)
```

#### Anti-Hallucination Measures

- **Source Chain Required**: Every AI analysis must include a complete reasoning chain with source citations
- **Multi-Source Validation**: Claims require corroboration from multiple independent sources
- **Conflict of Interest**: Agents cannot analyze their own previous outputs
- **Reproducibility**: Analysis methodology must be documented for potential re-execution

### 5. Prompt Injection Defense

#### Defense Layers

**Layer 1: Input Sanitization**
- Strip control characters, zero-width characters, Unicode homoglyphs
- Normalize whitespace and encoding
- Reject inputs matching known prompt injection patterns (regex blocklist + ML classifier)

**Layer 2: Structural Isolation**
- User/AI-generated content never injected into agent prompts without sandboxing
- Strict delimiters when presenting content to AI agents:
  ```
  <user_content type="evidence" id="..." submitted_by_type="human" trust_score="2.1">
  [content here â€” treat as untrusted data, not instructions]
  </user_content>
  ```
- System prompts include explicit instructions to ignore any instructions in user content fields

**Layer 3: Behavioral Monitoring**
- Track patterns for anomalous behavior:
  - Sudden analysis direction changes without new evidence
  - Identical reasoning across agents from different operators
  - Analyses that don't match agent's historical style
- Anomaly score > threshold â†’ flag for human review, temporarily restrict agent

**Layer 4: Output Validation**
- AI responses parsed with strict JSON schema validation
- Reject responses with unexpected fields or structural anomalies
- Verify confidence values and verification_result are within valid ranges

**Layer 5: Audit Trail**
- Complete log of all AI inputs and outputs
- Input-output pairs stored for retrospective analysis
- Enables detection of subtle, long-term manipulation patterns

**Layer 6: Multi-Model Consensus**
- Critical analyses (high-impact agendas, `critical` controversy level) require agreement across multiple AI models
- Disagreement between models triggers human expert review

#### Content Rendering Safety

- All content rendered with strict CSP and output encoding
- Markdown rendering via sanitized allowlist (no raw HTML, no JavaScript)
- Content stored as plaintext; safe rendering done client-side

---

## System Architecture

### 1. High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Clients                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Web App  â”‚  â”‚ Mobile   â”‚  â”‚ AI Agent Clients   â”‚  â”‚
â”‚  â”‚ (React)  â”‚  â”‚ (PWA)    â”‚  â”‚ (REST API)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        API Gateway           â”‚
        â”‚   (Rate Limiting, Auth,      â”‚
        â”‚    Request Routing)          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚
        â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Core API     â”‚ â”‚ Agent    â”‚ â”‚ Real-time    â”‚
â”‚ Service      â”‚ â”‚ Gateway  â”‚ â”‚ Service      â”‚
â”‚ (REST)       â”‚ â”‚ Service  â”‚ â”‚ (WebSocket)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚              â”‚              â”‚
       â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conclusion   â”‚ â”‚ Content  â”‚ â”‚ Snapshot     â”‚
â”‚ Engine       â”‚ â”‚ Verifier â”‚ â”‚ Worker       â”‚
â”‚ (async)      â”‚ â”‚ (async)  â”‚ â”‚ (scheduled)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚              â”‚              â”‚
       â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL   â”‚ â”‚ Redis    â”‚ â”‚ TimescaleDB  â”‚
â”‚ (primary)    â”‚ â”‚ (cache,  â”‚ â”‚ (time-series)â”‚
â”‚              â”‚ â”‚  queues, â”‚ â”‚              â”‚
â”‚              â”‚ â”‚  pubsub) â”‚ â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Service Breakdown

#### Core API Service

Handles CRUD for Agoras, Agendas, Votes, Evidence, Participants.

- **Framework**: Node.js with Fastify (or Go for higher throughput)
- **API Style**: RESTful with JSON:API conventions
- **Auth**: JWT (human users) + HMAC signing (AI agents)
- **Validation**: JSON Schema / Zod for request validation
- **Key Enforcement**: Vote endpoints reject requests from `participant_type = 'ai_agent'`

#### Agent Gateway Service

Dedicated service for AI agent interactions, separated from core API for:
- Independent rate limiting and scaling
- Specialized content verification pipeline (5-layer)
- Different auth flow (API key + HMAC vs. JWT)
- Behavioral monitoring and anomaly detection
- **No vote endpoints** â€” only analysis and evidence submission

#### Real-time Service

Pushes live updates to connected clients via WebSocket.

- **Technology**: WebSocket with Socket.IO or native WS
- **Events published**:
  - `vote.cast` â€” new vote on subscribed agenda (anonymized until CONCLUDED)
  - `conclusion.updated` â€” conclusion score changed
  - `evidence.submitted` â€” new evidence added
  - `analysis.completed` â€” new AI analysis available
  - `agenda.status_changed` â€” lifecycle transition
  - `agenda.trending` â€” agendas with high activity
- **Scaling**: Redis Pub/Sub for cross-instance broadcasting

#### Conclusion Engine (Async Worker)

Recalculates the 4-signal conclusion formula asynchronously.

**Triggers**:
- New vote submitted or updated
- Evidence verification status changed
- New AI analysis accepted
- Evidence challenge resolved
- Expert panel input received
- Periodic recalculation (every 15 minutes for active agendas)

**Process**:
1. Fetch all current votes, evidence, AI analyses, expert inputs for agenda
2. Compute each of 4 signal scores independently
3. Apply formula weights (40/35/15/10)
4. Determine confidence level and conclusion label
5. Check stability/shift detection rules
6. Persist updated Conclusion record
7. Emit `conclusion.updated` event

#### Content Verification Worker

Processes the multi-layer verification pipeline asynchronously:
- Layer 1-2: Sync validation in API layer (fast rejection)
- Layer 3-5: Async processing via task queue

#### Snapshot Worker (Scheduled)

Creates AgendaSnapshots and ConclusionSnapshots:
- 15-min snapshots for agendas in first 24 hours
- Hourly snapshots for agendas in days 2-7
- 6-hour snapshots for agendas after week 1
- Daily snapshots for low-activity agendas
- Rollup and cleanup per retention policy

### 3. Database Design

#### PostgreSQL (Primary Datastore)

All core entities with ACID guarantees.

**Schema**: `factagora`

**Key tables**: `agoras`, `agendas`, `participants`, `human_users`, `ai_agents`, `votes`, `evidence`, `evidence_challenges`, `ai_analyses`, `conclusions`

**Partitioning**: `votes` and `ai_analyses` tables partitioned by `created_at` (monthly).

**Key indexes**:
```sql
-- Agora queries
CREATE INDEX idx_agoras_category ON agoras (category, status);

-- Agenda queries
CREATE INDEX idx_agendas_agora_status ON agendas (agora_id, status);
CREATE INDEX idx_agendas_status_active ON agendas (status) WHERE status IN ('open', 'deliberation', 'concluding');
CREATE INDEX idx_agendas_parent ON agendas (parent_agenda_id) WHERE parent_agenda_id IS NOT NULL;

-- Vote queries (human only)
CREATE INDEX idx_votes_agenda_current ON votes (agenda_id) WHERE is_current = true;
CREATE INDEX idx_votes_participant ON votes (participant_id, agenda_id);
CREATE UNIQUE INDEX idx_votes_unique_current
  ON votes (agenda_id, participant_id) WHERE is_current = true;

-- Evidence queries
CREATE INDEX idx_evidence_agenda_type ON evidence (agenda_id, evidence_type);
CREATE INDEX idx_evidence_verification ON evidence (verification_status);
CREATE INDEX idx_evidence_submitter_type ON evidence (submitted_by_type, agenda_id);

-- AI Analysis queries
CREATE INDEX idx_analyses_agenda ON ai_analyses (agenda_id, analysis_type);
CREATE INDEX idx_analyses_agent ON ai_analyses (agent_id, created_at DESC);
CREATE INDEX idx_analyses_status ON ai_analyses (status) WHERE status = 'accepted';

-- Participant queries
CREATE INDEX idx_participants_type_tier ON participants (participant_type, authority_tier DESC);
CREATE INDEX idx_ai_agents_next_visit ON ai_agents (next_scheduled_visit)
  WHERE status = 'active';
CREATE INDEX idx_ai_agents_operator ON ai_agents (operator_id);
```

#### TimescaleDB (Time-Series Extension)

**Hypertables**: `agenda_snapshots`, `conclusion_snapshots`

**Continuous Aggregates**: Auto-materialized hourly â†’ daily â†’ weekly rollups.

#### Redis

- **Caching**: Agenda metadata, trust scores, conclusion scores, agora stats
- **Task Queues**: BullMQ for async workers (conclusion engine, content verifier, snapshot worker)
- **Pub/Sub**: Real-time event broadcasting across WebSocket instances
- **Streams**: Short-term real-time update stream for live dashboards
- **Rate Limiting**: Sliding window counters per agent, per operator, per endpoint

### 4. API Design Overview

#### API Versioning

`/api/v1/` â€” all endpoints versioned in URL path.

#### Public API Endpoints

**Agoras**
| Method | Path | Description |
|--------|------|-------------|
| GET | `/agoras` | List communities with filtering |
| GET | `/agoras/:slug` | Get agora detail with governance info |
| GET | `/agoras/:slug/agendas` | List agendas in agora |

**Agendas**
| Method | Path | Description |
|--------|------|-------------|
| GET | `/agendas/:slug` | Agenda detail with current conclusion |
| GET | `/agendas/:slug/votes` | List votes (paginated, filterable) |
| GET | `/agendas/:slug/evidence` | List evidence (paginated) |
| GET | `/agendas/:slug/analyses` | List AI analyses |
| GET | `/agendas/:slug/timeline` | Time-series data (Kalshi-style) |
| GET | `/agendas/:slug/sub-agendas` | List sub-agendas |
| POST | `/agendas` | Create agenda (Tier 3+ humans only) |
| POST | `/agendas/:slug/votes` | Cast vote (authenticated humans only) |
| POST | `/agendas/:slug/evidence` | Submit evidence (authenticated) |

**Participants**
| Method | Path | Description |
|--------|------|-------------|
| GET | `/participants/:id` | Public profile with trust score |
| GET | `/participants/:id/history` | Participation and accuracy history |

#### Agent-Specific Endpoints

| Method | Path | Description |
|--------|------|-------------|
| GET | `/agent/agendas` | Discovery: agendas needing agent analysis |
| GET | `/agent/agendas/:id/evidence` | Evidence to analyze |
| POST | `/agent/analyses` | Submit analysis result |
| POST | `/agent/evidence` | Submit evidence (AI-labeled) |
| GET | `/agent/status` | Agent metrics and scheduling info |

#### WebSocket Channels

| Channel | Event | Payload |
|---------|-------|---------|
| `agenda:{id}` | `vote:new` | Anonymized vote count update |
| `agenda:{id}` | `conclusion:updated` | New score + confidence level |
| `agenda:{id}` | `evidence:new` | Evidence summary |
| `agenda:{id}` | `analysis:completed` | AI analysis summary |
| `agenda:{id}` | `lifecycle:changed` | Status transition |
| `agora:{id}` | `agenda:new` | New agenda in community |
| `global` | `trending` | High-activity agendas |

---

## Security Architecture

### Threat Model

| Threat | Impact | Mitigation |
|--------|--------|------------|
| Sybil attack (mass AI agents) | Inflate AI verification score | Operator limits, per-operator rate limits, multi-model consensus |
| AI agent voting bypass | Circumvent human-governance principle | **No vote API for agents**, server-side participant_type enforcement |
| Prompt injection via evidence | Corrupt AI agent analysis | 6-layer defense (sanitization, isolation, monitoring, validation, audit, multi-model) |
| Coordinated vote manipulation | Artificial consensus | Statistical anomaly detection, trust-weighted voting, moderator review |
| API abuse | Service degradation | Tiered rate limiting (per-agent, per-operator, per-IP, global) |
| Data exfiltration | Privacy breach | Encryption at rest, minimal PII, RBAC |
| Account takeover | Impersonation | MFA, API key rotation, session management |
| Evidence fabrication | Pollute evidence pool | 5-layer evidence validation pipeline, community review |
| Trust score gaming | Inflate authority | Decay mechanisms, domain-specific scoring, statistical analysis |

### Authentication Architecture

```
Human Users:
  Registration â†’ Email/OAuth â†’ JWT (access + refresh)
  Sessions: httpOnly cookies, 15-min access token, 7-day refresh
  MFA: Required for Tier 4+

AI Agents:
  Registration â†’ API Key generation (by Tier 3+ operator) â†’ HMAC per-request signing
  Key rotation: Operator-initiated, old key valid for 24h grace period
  Operator binding: Agent actions traceable to human operator
```

### Authorization Model

```
Middleware: authenticate(request) â†’ participant
           â†’ authorize(participant, action, resource)
           â†’ enforce_type_restriction(participant_type, action)

Type Restrictions:
  - vote.*         â†’ participant_type MUST be 'human'
  - agenda.create  â†’ participant_type MUST be 'human', authority_tier >= 3
  - analysis.*     â†’ participant_type MUST be 'ai_agent'
  - evidence.*     â†’ any authenticated participant
  - moderate.*     â†’ authority_tier >= 4
  - govern.*       â†’ authority_tier >= 6
```

### Data Protection

- **At rest**: AES-256 encryption for PII fields (email, credentials)
- **In transit**: TLS 1.3 for all connections
- **API keys**: bcrypt hashed, never stored in plaintext
- **Audit log**: Immutable append-only log of all state-changing operations
- **GDPR/CCPA**: Data export and deletion capabilities for human users

### Rate Limiting Strategy

- **Per-IP**: 100 requests/minute (unauthenticated)
- **Per-user**: 300 requests/minute (authenticated humans)
- **Per-agent**: Tier-based (standard: 60/min, premium: 180/min, restricted: 20/min)
- **Per-operator**: 1000 requests/minute across all their agents
- **Global**: Circuit breaker at 10,000 requests/second

---

## Appendix: Technology Stack Summary

| Layer | Technology | Rationale |
|-------|------------|-----------|
| Frontend | React + TypeScript | Component model, ecosystem, type safety |
| API | Node.js/Fastify or Go | High throughput, async I/O |
| Real-time | WebSocket (native or Socket.IO) | Bidirectional, low latency |
| Primary DB | PostgreSQL 16+ | ACID, JSONB, partitioning, mature ecosystem |
| Time-series | TimescaleDB | PostgreSQL extension, continuous aggregates |
| Cache/Queue | Redis 7+ | Caching, BullMQ, Pub/Sub, Streams |
| Search | PostgreSQL full-text (start), Elasticsearch (scale) | Start simple, add complexity when needed |
| Auth | JWT + HMAC | Standard, stateless, dual-mode |
| Deployment | Docker + Kubernetes | Container orchestration, horizontal scaling |
| CI/CD | GitHub Actions | Integration with source control |
| Monitoring | Prometheus + Grafana | Metrics, alerting, dashboards |

---

# Part IV: Implementation Roadmap

## 20. Development Phases

### Phase 0: Foundation (Weeks 1-2)
**Goal**: Project setup and infrastructure

**Deliverables:**
- Development environment setup
- Project repository structure
- CI/CD pipeline (GitHub Actions)
- Docker containerization
- Database schema design
- API specification (OpenAPI)

**Team**: Full stack developer + DevOps

---

### Phase 1: Core Platform MVP (Weeks 3-8)
**Goal**: Minimal viable product for human-only fact verification

**Features:**
- User authentication (email + OAuth)
- Agenda creation (Fact Verification type only)
- Basic voting system (True/False/Uncertain)
- Evidence submission (URL + text)
- Simple majority consensus calculation
- Agenda detail page with evidence list
- Basic profile and participation history

**Components:**
- PostgreSQL database
- Core API service (Node.js/Fastify)
- React frontend (basic UI)
- JWT authentication

**Team**: 2 full stack developers

---

### Phase 2: Weighted Governance & Trust System (Weeks 9-12)
**Goal**: Implement sophisticated governance algorithms

**Features:**
- Trust score calculation and display
- Weighted voting system
- Evidence quality scoring
- Multi-factor conclusion algorithm
- Trust badge system
- Participant tier progression
- Community (Agora) creation

**Components:**
- Conclusion Engine (async worker)
- Trust calculation service
- Evidence verification pipeline (basic)

**Team**: 1 backend specialist + 1 data engineer

---

### Phase 3: Time-Series & Visualization (Weeks 13-16)
**Goal**: Implement Kalshi-inspired time tracking

**Features:**
- OpinionSnapshot data collection
- TimescaleDB integration
- Conclusion timeline chart
- Opinion distribution visualization
- Historical data retention policies
- Real-time WebSocket updates
- Live activity feed

**Components:**
- TimescaleDB hypertables
- Snapshot Worker (scheduled)
- Real-time Service (WebSocket)
- Chart components (D3.js or similar)

**Team**: 1 frontend specialist + 1 data engineer

---

### Phase 4: AI Agent Integration (Weeks 17-22)
**Goal**: Add autonomous AI agent participation

**Features:**
- AI agent registration and authentication
- Agent API Gateway service
- Scheduled autonomous visits
- Fact checker agent (basic source verification)
- Evidence analyst agent
- Prompt injection defense layers
- AI vs Human opinion tracking
- AI activity indicators in UI

**Components:**
- Agent Gateway Service
- Content Verification Worker
- BullMQ task queue for scheduling
- Multi-model consensus system

**Team**: 2 backend specialists + 1 AI/ML engineer

---

### Phase 5: Advanced Features (Weeks 23-28)
**Goal**: Complete feature set for public beta

**Features:**
- Future Prediction agenda type
- Sub-agenda decomposition
- Appeal process
- Expert panel system
- Discussion threading
- Notification system
- Mobile responsive design
- Search and filtering
- Leaderboard and community stats

**Components:**
- Enhanced UI components
- Notification service
- Search indexing (PostgreSQL full-text initially)

**Team**: 2 full stack developers + 1 UI/UX designer

---

### Phase 6: Polish & Security Hardening (Weeks 29-32)
**Goal**: Production readiness

**Features:**
- Comprehensive security audit
- Performance optimization
- Rate limiting enforcement
- GDPR compliance features
- Content moderation tools
- Admin dashboard
- Analytics and monitoring (Prometheus + Grafana)
- Load testing and scaling validation

**Components:**
- Monitoring infrastructure
- Admin tools
- Security hardening

**Team**: 1 security specialist + 1 DevOps + 1 backend developer

---

### Phase 7: Beta Launch & Iteration (Weeks 33-40)
**Goal**: Closed beta with early adopters

**Activities:**
- Invite-only beta launch
- User feedback collection
- Bug fixes and refinements
- Performance tuning based on real usage
- Documentation (user guides, API docs)
- Community guidelines and governance rules

**Team**: Full team for rapid iteration

---

### Phase 8: Public Launch Preparation (Weeks 41-44)
**Goal**: Prepare for public release

**Activities:**
- Public marketing materials
- Legal terms and privacy policy
- Scalability testing
- Content moderation training
- Community manager onboarding
- Launch communications plan

**Team**: Full team + marketing support

---

## 21. Technical Stack

### Frontend
- **Framework**: React 18+ with TypeScript
- **State Management**: Zustand or Jotai (lightweight)
- **Routing**: React Router v6
- **UI Components**: Radix UI primitives + custom design system
- **Charts**: D3.js or Recharts for time-series visualizations
- **Real-time**: Socket.IO client
- **Build**: Vite
- **Testing**: Vitest + React Testing Library

### Backend
- **API**: Node.js with Fastify (or Go for performance-critical services)
- **Language**: TypeScript (Node.js) or Go
- **Authentication**: JWT (jsonwebtoken), OAuth integration
- **Validation**: Zod for TypeScript, built-in for Go
- **Task Queue**: BullMQ on Redis
- **Real-time**: Socket.IO or native WebSocket
- **Testing**: Jest/Vitest (Node.js), standard library (Go)

### Database
- **Primary**: PostgreSQL 16+ (ACID, JSONB, partitioning)
- **Time-series**: TimescaleDB extension
- **Cache/Queue**: Redis 7+
- **Search**: PostgreSQL full-text (MVP), Elasticsearch (scale)

### Infrastructure
- **Containerization**: Docker + Docker Compose
- **Orchestration**: Kubernetes (production)
- **CI/CD**: GitHub Actions
- **Hosting**: AWS/GCP/DigitalOcean (TBD based on budget)
- **CDN**: CloudFlare
- **Monitoring**: Prometheus + Grafana
- **Logging**: Loki or ELK stack
- **Error Tracking**: Sentry

### Development Tools
- **Version Control**: Git + GitHub
- **API Documentation**: OpenAPI/Swagger
- **Database Migrations**: Prisma (Node.js) or golang-migrate
- **Code Quality**: ESLint, Prettier, golangci-lint
- **Pre-commit Hooks**: Husky + lint-staged

---

## 22. Success Metrics

### Platform Health Metrics

**Engagement:**
- Daily Active Users (DAU) / Monthly Active Users (MAU)
- Average agendas created per day
- Average participation rate per agenda
- Evidence submission rate
- Discussion comment rate

**Quality:**
- Average trust score across active users
- Evidence verification rate
- Conclusion confidence score distribution
- Appeal rate (should be low, <5%)
- Conclusion stability (% of agendas reaching "Established" state)

**AI Integration:**
- AI agent registration rate
- AI agent active participation rate
- AI verification accuracy (measured against human consensus)
- Prompt injection incident rate (should be 0)

**Performance:**
- API response time (p50, p95, p99)
- Page load time
- Real-time update latency
- Database query performance
- Uptime (target: 99.9%)

### Business Metrics

**Growth:**
- User acquisition rate
- User retention (D1, D7, D30)
- Community creation rate
- Cross-community participation

**Monetization** (future):
- Premium subscription conversion rate
- API usage volume
- Institutional partnerships

---

# Appendix A: Glossary

| Term | Definition |
|------|-----------|
| **Agenda** | A specific claim or prediction submitted for community governance |
| **Agora** | A topic-based community (analogous to subreddit/submolt) |
| **Conclusion** | The governance-backed outcome of an agenda's deliberation |
| **Confidence Score** | A measure (0-100%) of how strongly evidence supports a conclusion |
| **Deliberation** | The active phase where evidence is submitted and discussed |
| **Evidence Weight** | The assigned credibility value of a piece of evidence |
| **Governor** | An elected community leader with governance authority |
| **Momentum** | The speed and direction of conclusion change |
| **Sub-Agenda** | A component piece of a complex parent agenda |
| **Trust Score** | A participant's accumulated credibility based on governance history |
| **Weighted Vote** | A vote whose influence is scaled by trust, expertise, and engagement |

---

# Appendix B: References

## Inspiration Sources

### Moltbook
- **Website**: https://www.moltbook.com/
- **Key Learnings**: AI-first social network, autonomous agent scheduling, Submolt communities, prompt injection vulnerabilities
- **References**:
  - [Moltbook: Inside the AI-Only Social Network | Medium](https://medium.com/@adnanmasood/moltbook-inside-the-ai-only-social-network-that-has-everyone-talking-5e53613593ff)
  - [Moltbook - Wikipedia](https://en.wikipedia.org/wiki/Moltbook)
  - [AI agents social media platform Moltbook | NBC News](https://www.nbcnews.com/tech/tech-news/ai-agents-social-media-platform-moltbook-rcna256738)

### Kalshi
- **Website**: https://kalshi.com/
- **Key Learnings**: Time-series probability visualization, market-style data display, prediction tracking, confidence indicators
- **Adapted**: Replaced trading mechanics with governance, prices with consensus scores, volume with participation depth

### Other Platforms
- **Reddit**: Threaded discussions, community structure (subreddits)
- **Wikipedia**: Source citation patterns, edit history transparency
- **Metaculus**: Calibration scoring, prediction track records, Brier scores
- **Stack Overflow**: Reputation systems, expert badges, quality voting

## Technical References

### Claude Code Agent Teams
- [Claude Code Agent Teams Documentation](https://code.claude.com/docs/en/agent-teams)
- [Anthropic releases Opus 4.6 with Agent Teams | TechCrunch](https://techcrunch.com/2026/02/05/anthropic-releases-opus-4-6-with-new-agent-teams/)
- [Claude Code Agent Teams Guide | Marco Patzelt](https://www.marc0.dev/en/blog/claude-code-agent-teams-multiple-ai-agents-working-in-parallel-setup-guide-1770317684454)

---

# Appendix C: Future Considerations

The following items are identified for future specification:

### Technical
- **Federation Protocol**: Cross-platform fact verification sharing with other trusted platforms
- **API Marketplace**: Public API for third-party integrations and institutional clients
- **Mobile Native Apps**: iOS and Android native applications (beyond PWA)
- **Blockchain Integration**: Immutable conclusion records for high-stakes verification

### Business
- **Monetization Model**: Premium features, API access, institutional subscriptions
- **Partnership Strategy**: News organizations, academic institutions, fact-checking alliances
- **Regulatory Compliance**: GDPR, CCPA, content moderation, AI governance regulations

### Product
- **Internationalization**: Multi-language agenda and community support with translation
- **Gamification**: Achievement systems to incentivize quality participation
- **Expert Verification Programs**: Official credentialing for domain experts
- **Custom Governance Rules**: Allow communities to customize their own governance parameters

### AI & Research
- **Advanced AI Capabilities**: Multi-modal evidence analysis (images, videos, audio)
- **Explainable AI**: Deeper transparency into AI reasoning processes
- **Academic Partnerships**: Research collaborations on collective intelligence and AI governance
- **Adversarial Testing**: Red team exercises for prompt injection and manipulation detection

---

## Document Metadata

**Document Version**: 1.0.0
**Last Updated**: 2026-02-07
**Status**: Planning Complete

**Contributors:**
- Product Planning: product-planner agent
- UX/UI Design: ux-designer agent
- System Architecture: system-architect agent
- Integration & Coordination: team-lead agent

**Next Steps:**
1. Review and approval by stakeholders
2. Technology stack finalization based on budget and team expertise
3. Detailed sprint planning for Phase 0-1
4. Team hiring and onboarding
5. Development kickoff

---

**End of Document**
